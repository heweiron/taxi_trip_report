{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e56ef6e5",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "### Team: Data Miner(Weirong He, Michael Gainey, Tri Pham)\n",
    "### Topic: Taxi Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b9260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604bdc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/11/17 10:52:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext()\n",
    "session = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781bd25d",
   "metadata": {},
   "source": [
    "## Data Process\n",
    "Data set could be download at https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n",
    "In this project, we are focusing on year 2020, so we have 12 month taxi data in 2020. However, this dataset is too large for this project, so we decide to only take data at the first week of each month which will lead to result of 5M records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e94f83ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_record_1 = session.read.csv(\"data/records/yellow_tripdata_2020-01.csv\", header=True)\n",
    "taxi_record_2 = session.read.csv(\"data/records/yellow_tripdata_2020-02.csv\", header=True)\n",
    "taxi_record_3 = session.read.csv(\"data/records/yellow_tripdata_2020-03.csv\", header=True)\n",
    "taxi_record_4 = session.read.csv(\"data/records/yellow_tripdata_2020-04.csv\", header=True)\n",
    "taxi_record_5 = session.read.csv(\"data/records/yellow_tripdata_2020-05.csv\", header=True)\n",
    "taxi_record_6 = session.read.csv(\"data/records/yellow_tripdata_2020-06.csv\", header=True)\n",
    "taxi_record_7 = session.read.csv(\"data/records/yellow_tripdata_2020-07.csv\", header=True)\n",
    "taxi_record_8 = session.read.csv(\"data/records/yellow_tripdata_2020-08.csv\", header=True)\n",
    "taxi_record_9 = session.read.csv(\"data/records/yellow_tripdata_2020-09.csv\", header=True)\n",
    "taxi_record_10 = session.read.csv(\"data/records/yellow_tripdata_2020-10.csv\", header=True)\n",
    "taxi_record_11 = session.read.csv(\"data/records/yellow_tripdata_2020-11.csv\", header=True)\n",
    "taxi_record_12 = session.read.csv(\"data/records/yellow_tripdata_2020-12.csv\", header=True)\n",
    "location_df = session.read.csv(\"data/taxi+_zone_lookup.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee7258f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = (\"2020-01-01\",  \"2020-01-07\")\n",
    "taxi_record_1 = taxi_record_1.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-02-01\",  \"2020-02-07\")\n",
    "taxi_record_2 = taxi_record_2.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-03-01\",  \"2020-03-07\")\n",
    "taxi_record_3 = taxi_record_3.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-04-01\",  \"2020-04-07\")\n",
    "taxi_record_4 = taxi_record_4.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-05-01\",  \"2020-05-07\")\n",
    "taxi_record_5 = taxi_record_5.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-06-01\",  \"2020-06-07\")\n",
    "taxi_record_6 = taxi_record_6.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-07-01\",  \"2020-07-07\")\n",
    "taxi_record_7 = taxi_record_7.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-08-01\",  \"2020-08-07\")\n",
    "taxi_record_8 = taxi_record_8.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-09-01\",  \"2020-09-07\")\n",
    "taxi_record_9 = taxi_record_9.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-10-01\",  \"2020-10-07\")\n",
    "taxi_record_10 = taxi_record_10.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-11-01\",  \"2020-11-07\")\n",
    "taxi_record_11 = taxi_record_11.where(F.col('tpep_pickup_datetime').between(*dates))\n",
    "dates = (\"2020-12-01\",  \"2020-12-07\")\n",
    "taxi_record_12 = taxi_record_12.where(F.col('tpep_pickup_datetime').between(*dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abdd7c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_record = (taxi_record_1.union(taxi_record_2).union(taxi_record_3)\n",
    "               .union(taxi_record_4).union(taxi_record_5).union(taxi_record_6)\n",
    "               .union(taxi_record_7).union(taxi_record_8).union(taxi_record_9)\n",
    "               .union(taxi_record_10).union(taxi_record_11).union(taxi_record_12)\n",
    "               .drop(\"VendorID\", \"RatecodeID\", \"payment_type\", \"store_and_fwd_flag\",\n",
    "                     \"improvement_surcharge\", \"mta_tax\", \"tolls_amount\", \"congestion_surcharge\")\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "457c7249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(tpep_pickup_datetime='2020-01-01 00:28:15', tpep_dropoff_datetime='2020-01-01 00:33:03', passenger_count='1', trip_distance='1.20', PULocationID='238', DOLocationID='239', fare_amount='6', extra='3', tip_amount='1.47', total_amount='11.27')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taxi_record.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64c047e",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "We can use Machine Learning to help taxi driver to predict the fare amout of next trip. In real life, taxi passengers alway like to ask the price right after they stating the destination location. Many drivers with more experience can quickly response a rough price. And this model can look through 5M trips to become a experienced taxi driver and make a prediction of the fare amount based on the pickup location and drop off location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c8ee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data process in spark\n",
    "loc_price = taxi_record.select(F.col(\"PULocationID\").alias(\"PU\"),\n",
    "                   F.col(\"DOLocationID\").alias(\"DO\"),\n",
    "                   F.col(\"fare_amount\").alias(\"Price\"))\n",
    "# filter null value record and unknown record(locationID: 264 and 265 are unknown)\n",
    "loc_price = loc_price.filter(loc_price.PU.isNotNull() & loc_price.PU.between(1, 263)\n",
    "                             & loc_price.DO.isNotNull() & loc_price.DO.between(1, 263)\n",
    "                             & loc_price.Price.isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d49359",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.18 s, sys: 345 ms, total: 1.52 s\n",
      "Wall time: 43.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert spark df to pandas df\n",
    "loc_price.write.mode(\"overwrite\").parquet(\"loc_price.parquet\")\n",
    "pd_df = pq.read_pandas('loc_price.parquet').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fb3fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data process in pandas df\n",
    "pickup = np.array(pd_df.PU).astype(float)\n",
    "dropoff = np.array(pd_df.DO).astype(float)\n",
    "\n",
    "location = np.vstack((pickup, dropoff)).T\n",
    "price = np.array(pd_df.Price).astype(float)\n",
    "# data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(location, price, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a40259e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 42s, sys: 3.25 s, total: 2min 45s\n",
      "Wall time: 2min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit model\n",
    "regr = RandomForestRegressor(max_depth=3, random_state=0)\n",
    "regr.fit(X_train, y_train)\n",
    "y_pred = regr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f85fcff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "price accuracy(accept +- 5 error) : 0.56\n",
      "Coefficient of determination: 0.23\n",
      "Mean squared error: 93.08\n"
     ]
    }
   ],
   "source": [
    "def cal_accuracy(pred, actual):\n",
    "    count = 0;\n",
    "    for i in range(len(actual)):\n",
    "        if (abs(pred[i] - actual[i]) <= 5):\n",
    "            count = count + 1\n",
    "    accuracy = count/len(actual)\n",
    "    return accuracy\n",
    "print(\"price accuracy(accept +- 5 error) : %.2f\" %cal_accuracy(y_pred, y_test))\n",
    "print(\"Coefficient of determination: %.2f\" % r2_score(y_test, y_pred))\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd20a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
